---
AWSTemplateFormatVersion: "2010-09-09"
Description: HTCondor Service Catalog Product
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Network Configuration
        Parameters:
          - pNamePrefix
          - pVPCID
          - pSubnets
          - pAllowedCidrIp
      - Label:
          default: Controller Configuration
        Parameters:
          - pControlNodeInstanceType
          - pControlNodeVolumeSize
          - pControlNodeAmiId
      - Label:
          default: Worker Configuration
        Parameters:
          - pNumberOfWorkerNodes
          - pWorkerNodeInstanceType
          - pWorkerNodeVolumeSize
          - pWorkerNodeAmiId
      - Label:
          default: Spot Instance Configuration
        Parameters:
          - pUseSpotInstances
          - pWorkerSpotNodeInstanceType1
          - pWorkerSpotNodeInstanceType2
          - pWorkerSpotNodeInstanceType3
      - Label:
          default: Advanced Configuration
        Parameters:
          - pEfsId
          - pControlNodeInstanceProfile
          - pWorkerNodeInstanceProfile
    ParameterLabels:
      pNamePrefix:
        default: Name Prefix
      pVPCID:
        default: VPC
      pSubnets:
        default: Subnets (Select 3)
      pAllowedCidrIp:
        default: CIDR Range with access to the Control Node
      pControlNodeInstanceType:
        default: Control Node Instance Type
      pControlNodeVolumeSize:
        default: Control Node Volume Size
      pControlNodeAmiId:
        default: Control Node AMI ID
      pNumberOfWorkerNodes:
        default: Number of Worker Nodes to launch
      pWorkerNodeInstanceType:
        default: Worker Node Instance Type
      pWorkerNodeVolumeSize:
        default: Worker Node Volume Size
      pWorkerNodeAmiId:
        default: Worker Node AMI ID
      pUseSpotInstances:
        default: Use Spot Instances
      pWorkerSpotNodeInstanceType1:
        default: (Optional) Spot Instance Type 1
      pWorkerSpotNodeInstanceType2:
        default: (Optional) Spot Instance Type 2
      pWorkerSpotNodeInstanceType3:
        default: (Optional) Spot Instance Type 3
      pEfsId:
        default: Existing EFS ID
      pControlNodeInstanceProfile:
        default: Control Node Instance Profile
      pWorkerNodeInstanceProfile:
        default: Worker Node Instance Profile

Parameters:
  pNamePrefix:
    Type: String
    Default: ""
    Description: Enter a unique prefix to help identify your cluster's specific resources
  pVPCID:
    Description: VPC Id for deployment
    Type: AWS::EC2::VPC::Id
  pSubnets:
    Description: Subnets for deployment
    Type: List<AWS::EC2::Subnet::Id>
  pAllowedCidrIp:
    Type: String
    Default: 0.0.0.0/0
    AllowedPattern: '((\d{1,3})\.){3}\d{1,3}/\d{1,2}'
    Description: Input the CIDR range of the selected VPC.

  pNumberOfWorkerNodes:
    Description: The number of Worker Nodes to spin up. Update this parameter to alter available compute power or save on costs.
    Type: Number
    Default: 2
    MinValue: 0
  pWorkerNodeVolumeSize:
    Description: The EBS volume size of the Worker Nodes.
    Type: Number
    Default: 64
    MinValue: 20
  pWorkerNodeInstanceType:
    Description: Instance type for Worker Nodes
    Type: String
    Default: t3.micro
    AllowedValues:
      - t3.nano
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - t3a.nano
      - t3a.micro
      - t3a.small
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - c5.metal
      - c5ad.large
      - c5ad.xlarge
      - c5ad.2xlarge
      - c5ad.4xlarge
      - c5ad.8xlarge
      - c5ad.12xlarge
      - c5ad.16xlarge
      - c5ad.24xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.12xlarge
      - c5d.18xlarge
      - c5d.24xlarge
      - c5d.metal
      - c5n.large
      - c5n.xlarge
      - c5n.2xlarge
      - c5n.4xlarge
      - c5n.9xlarge
      - c5n.18xlarge
      - c5n.metal
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.16xlarge
      - m5.24xlarge
      - m5.metal
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.16xlarge
      - m5a.24xlarge
      - m5ad.large
      - m5ad.xlarge
      - m5ad.2xlarge
      - m5ad.4xlarge
      - m5ad.8xlarge
      - m5ad.12xlarge
      - m5ad.16xlarge
      - m5ad.24xlarge
      - m5d.large
      - m5d.xlarge
      - m5d.2xlarge
      - m5d.4xlarge
      - m5d.8xlarge
      - m5d.12xlarge
      - m5d.16xlarge
      - m5d.24xlarge
      - m5dn.large
      - m5dn.xlarge
      - m5dn.2xlarge
      - m5dn.4xlarge
      - m5dn.8xlarge
      - m5dn.12xlarge
      - m5dn.16xlarge
      - m5dn.24xlarge
      - m5n.large
      - m5n.xlarge
      - m5n.2xlarge
      - m5n.4xlarge
      - m5n.8xlarge
      - m5n.12xlarge
      - m5n.16xlarge
      - m5n.24xlarge
  pWorkerNodeAmiId:
    Description: The AMI to run the HTCondor Worker nodes on. Needs to have minimum required software installed.
    Type: AWS::EC2::Image::Id
    Default: ami-0df24e148fdb9f1d8

  pControlNodeVolumeSize:
    Description: "The EBS volume size of the Control Node. NOTE: AWS Elastic File System storage is comes configured on the Control Node."
    Type: Number
    Default: 64
    MinValue: 20
  pControlNodeInstanceType:
    Description: Instance type for the Control Node
    Type: String
    Default: t3.micro
    AllowedValues:
      - t3.nano
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - t3a.nano
      - t3a.micro
      - t3a.small
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - c5.metal
      - c5ad.large
      - c5ad.xlarge
      - c5ad.2xlarge
      - c5ad.4xlarge
      - c5ad.8xlarge
      - c5ad.12xlarge
      - c5ad.16xlarge
      - c5ad.24xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.12xlarge
      - c5d.18xlarge
      - c5d.24xlarge
      - c5d.metal
      - c5n.large
      - c5n.xlarge
      - c5n.2xlarge
      - c5n.4xlarge
      - c5n.9xlarge
      - c5n.18xlarge
      - c5n.metal
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.16xlarge
      - m5.24xlarge
      - m5.metal
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.16xlarge
      - m5a.24xlarge
      - m5ad.large
      - m5ad.xlarge
      - m5ad.2xlarge
      - m5ad.4xlarge
      - m5ad.8xlarge
      - m5ad.12xlarge
      - m5ad.16xlarge
      - m5ad.24xlarge
      - m5d.large
      - m5d.xlarge
      - m5d.2xlarge
      - m5d.4xlarge
      - m5d.8xlarge
      - m5d.12xlarge
      - m5d.16xlarge
      - m5d.24xlarge
      - m5dn.large
      - m5dn.xlarge
      - m5dn.2xlarge
      - m5dn.4xlarge
      - m5dn.8xlarge
      - m5dn.12xlarge
      - m5dn.16xlarge
      - m5dn.24xlarge
      - m5n.large
      - m5n.xlarge
      - m5n.2xlarge
      - m5n.4xlarge
      - m5n.8xlarge
      - m5n.12xlarge
      - m5n.16xlarge
      - m5n.24xlarge
  pControlNodeAmiId:
    Description: The AMI to run the HTCondor Controller node on. Needs to have minimum required software installed.
    Type: AWS::EC2::Image::Id
    Default: ami-0df24e148fdb9f1d8

  pUseSpotInstances:
    Description: Whether to use Spot Instance for the worker nodes
    Type: String
    Default: "false"
    AllowedValues:
      - "true"
      - "false"
  pWorkerSpotNodeInstanceType1:
    Type: String
    Description: An additional instance type to use in the Spot Pool for Worker Instances
    Default: ''
    AllowedValues:
      - ''
      - t3.nano
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - t3a.nano
      - t3a.micro
      - t3a.small
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - c5.metal
      - c5ad.large
      - c5ad.xlarge
      - c5ad.2xlarge
      - c5ad.4xlarge
      - c5ad.8xlarge
      - c5ad.12xlarge
      - c5ad.16xlarge
      - c5ad.24xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.12xlarge
      - c5d.18xlarge
      - c5d.24xlarge
      - c5d.metal
      - c5n.large
      - c5n.xlarge
      - c5n.2xlarge
      - c5n.4xlarge
      - c5n.9xlarge
      - c5n.18xlarge
      - c5n.metal
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.16xlarge
      - m5.24xlarge
      - m5.metal
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.16xlarge
      - m5a.24xlarge
      - m5ad.large
      - m5ad.xlarge
      - m5ad.2xlarge
      - m5ad.4xlarge
      - m5ad.8xlarge
      - m5ad.12xlarge
      - m5ad.16xlarge
      - m5ad.24xlarge
      - m5d.large
      - m5d.xlarge
      - m5d.2xlarge
      - m5d.4xlarge
      - m5d.8xlarge
      - m5d.12xlarge
      - m5d.16xlarge
      - m5d.24xlarge
      - m5dn.large
      - m5dn.xlarge
      - m5dn.2xlarge
      - m5dn.4xlarge
      - m5dn.8xlarge
      - m5dn.12xlarge
      - m5dn.16xlarge
      - m5dn.24xlarge
      - m5n.large
      - m5n.xlarge
      - m5n.2xlarge
      - m5n.4xlarge
      - m5n.8xlarge
      - m5n.12xlarge
      - m5n.16xlarge
      - m5n.24xlarge
  pWorkerSpotNodeInstanceType2:
    Type: String
    Description: An additional instance type to use in the Spot Pool for Worker Instances
    Default: ''
    AllowedValues:
      - ''
      - t3.nano
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - t3a.nano
      - t3a.micro
      - t3a.small
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - c5.metal
      - c5ad.large
      - c5ad.xlarge
      - c5ad.2xlarge
      - c5ad.4xlarge
      - c5ad.8xlarge
      - c5ad.12xlarge
      - c5ad.16xlarge
      - c5ad.24xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.12xlarge
      - c5d.18xlarge
      - c5d.24xlarge
      - c5d.metal
      - c5n.large
      - c5n.xlarge
      - c5n.2xlarge
      - c5n.4xlarge
      - c5n.9xlarge
      - c5n.18xlarge
      - c5n.metal
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.16xlarge
      - m5.24xlarge
      - m5.metal
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.16xlarge
      - m5a.24xlarge
      - m5ad.large
      - m5ad.xlarge
      - m5ad.2xlarge
      - m5ad.4xlarge
      - m5ad.8xlarge
      - m5ad.12xlarge
      - m5ad.16xlarge
      - m5ad.24xlarge
      - m5d.large
      - m5d.xlarge
      - m5d.2xlarge
      - m5d.4xlarge
      - m5d.8xlarge
      - m5d.12xlarge
      - m5d.16xlarge
      - m5d.24xlarge
      - m5dn.large
      - m5dn.xlarge
      - m5dn.2xlarge
      - m5dn.4xlarge
      - m5dn.8xlarge
      - m5dn.12xlarge
      - m5dn.16xlarge
      - m5dn.24xlarge
      - m5n.large
      - m5n.xlarge
      - m5n.2xlarge
      - m5n.4xlarge
      - m5n.8xlarge
      - m5n.12xlarge
      - m5n.16xlarge
      - m5n.24xlarge
  pWorkerSpotNodeInstanceType3:
    Type: String
    Description: An additional instance type to use in the Spot Pool for Worker Instances
    Default: ''
    AllowedValues:
      - ''
      - t3.nano
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - t3a.nano
      - t3a.micro
      - t3a.small
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - c5.metal
      - c5ad.large
      - c5ad.xlarge
      - c5ad.2xlarge
      - c5ad.4xlarge
      - c5ad.8xlarge
      - c5ad.12xlarge
      - c5ad.16xlarge
      - c5ad.24xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.12xlarge
      - c5d.18xlarge
      - c5d.24xlarge
      - c5d.metal
      - c5n.large
      - c5n.xlarge
      - c5n.2xlarge
      - c5n.4xlarge
      - c5n.9xlarge
      - c5n.18xlarge
      - c5n.metal
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.16xlarge
      - m5.24xlarge
      - m5.metal
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.16xlarge
      - m5a.24xlarge
      - m5ad.large
      - m5ad.xlarge
      - m5ad.2xlarge
      - m5ad.4xlarge
      - m5ad.8xlarge
      - m5ad.12xlarge
      - m5ad.16xlarge
      - m5ad.24xlarge
      - m5d.large
      - m5d.xlarge
      - m5d.2xlarge
      - m5d.4xlarge
      - m5d.8xlarge
      - m5d.12xlarge
      - m5d.16xlarge
      - m5d.24xlarge
      - m5dn.large
      - m5dn.xlarge
      - m5dn.2xlarge
      - m5dn.4xlarge
      - m5dn.8xlarge
      - m5dn.12xlarge
      - m5dn.16xlarge
      - m5dn.24xlarge
      - m5n.large
      - m5n.xlarge
      - m5n.2xlarge
      - m5n.4xlarge
      - m5n.8xlarge
      - m5n.12xlarge
      - m5n.16xlarge
      - m5n.24xlarge

  pEfsId:
    Type: String
    Default: ""
    Description: Input the ID of an existing Elastic File System (fs-asdfasdf) to be attached to the Cluster Nodes. Leave blank to create a new filesystem.
  pControlNodeInstanceProfile:
    Type: String
    Default: ""
    Description: Leave blank to create a default role
  pWorkerNodeInstanceProfile:
    Type: String
    Default: ""
    Description: Leave blank to create a default role

Rules:
  SubnetsInVPC:
    Assertions:
      - Assert: !EachMemberIn
          - !ValueOfAll
            - AWS::EC2::Subnet::Id
            - VpcId
          - !RefAll 'AWS::EC2::VPC::Id'
        AssertDescription: All subnets must in the VPC
  Spot1UniqueWorkerType:
    RuleCondition: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType1, '' ] ]
    Assertions:
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType1, !Ref pWorkerNodeInstanceType ] ]
        AssertDescription: Spot Instance Type 1 CANNOT match Worker Node Instance Type
  Spot2UniqueWorkerType:
    RuleCondition: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType2, '' ] ]
    Assertions:
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType2, !Ref pWorkerNodeInstanceType ] ]
        AssertDescription: Spot Instance Type 2 CANNOT match Worker Node Instance Type
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType2, !Ref pWorkerSpotNodeInstanceType1 ] ]
        AssertDescription: Spot Instance Type 2 CANNOT match Spot Instance Type 1
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType1, '' ] ]
        AssertDescription: Must specify Spot Instance Types in order. Spot Instance Type 1 CANNOT be blank if Spot Instance Type 2 is specified.
  Spot3UniqueWorkerType:
    RuleCondition: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType3, '' ] ]
    Assertions:
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType3, !Ref pWorkerNodeInstanceType ] ]
        AssertDescription: Spot Instance Type 3 CANNOT match Worker Node Instance Type
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType3, !Ref pWorkerSpotNodeInstanceType1 ] ]
        AssertDescription: Spot Instance Type 3 CANNOT match Spot Instance Type 1
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType3, !Ref pWorkerSpotNodeInstanceType2 ] ]
        AssertDescription: Spot Instance Type 3 CANNOT match Spot Instance Type 2
      - Assert: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType2, '' ] ]
        AssertDescription: Must specify Spot Instance Types in order. Spot Instance Type 2 CANNOT be blank if Spot Instance Type 3 is specified.

Conditions:
  cCreateControlNodeInstanceProfile:  !Equals [ !Ref pControlNodeInstanceProfile, ""]
  cCreateWorkerNodeInstanceProfile: !Equals [ !Ref pWorkerNodeInstanceProfile, ""]

  cCreateFileSystem: !Equals [ !Ref pEfsId, "" ]

  cLaunchWorkerNode: !Not [ !Equals [ !Ref pNumberOfWorkerNodes, 0 ] ]
  cUseSpotInstances: !Equals [ !Ref pUseSpotInstances, true ]
  cSpotType1Exists: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType1, '' ] ]
  cSpotType2Exists: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType2, '' ] ]
  cSpotType3Exists: !Not [ !Equals [ !Ref pWorkerSpotNodeInstanceType3, '' ] ]


Resources:
  ControlNodeRole:
    Type: AWS::IAM::Role
    Condition: cCreateControlNodeInstanceProfile
    Metadata:
      cfn_nag:
        rules_to_suppress:
        - id: W11 # Cant predict resources
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
        - arn:aws:iam::aws:policy/ReadOnlyAccess
      Policies:
        - PolicyName: BootupPermissions
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: AutoScalingLifecycle
                Effect: Allow
                Action:
                  - autoscaling:CompleteLifecycleAction
                  - autoscaling:RecordLifecycleActionHeartbeat
                  - cloudformation:SignalResource
                  - ec2:*Tag*
                Resource: '*'
        - PolicyName: S3Access
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: S3Access
                Effect: Allow
                Action:
                  - s3:AbortMultipartUpload
                  - s3:DeleteObject*
                  - s3:Get*
                  - s3:List*
                  - s3:PutObject
                  - s3:Replicate*
                  - s3:RestoreObject
                Resource: '*'

  ControlNodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Condition: cCreateControlNodeInstanceProfile
    Properties:
      Path: "/"
      Roles:
        - !Ref ControlNodeRole

  WorkerNodeRole:
    Type: AWS::IAM::Role
    Condition: cCreateWorkerNodeInstanceProfile
    Metadata:
      cfn_nag:
        rules_to_suppress:
        - id: W11 # Cant predict resources
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
        - arn:aws:iam::aws:policy/ReadOnlyAccess
      Policies:
        - PolicyName: BootupPermissions
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: AutoScalingLifecycle
                Effect: Allow
                Action:
                  - autoscaling:CompleteLifecycleAction
                  - autoscaling:RecordLifecycleActionHeartbeat
                  - cloudformation:SignalResource
                  - ec2:*Tag*
                Resource: '*'
        - PolicyName: S3Access
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: S3Access
                Effect: Allow
                Action:
                  - s3:AbortMultipartUpload
                  - s3:DeleteObject*
                  - s3:Get*
                  - s3:List*
                  - s3:PutObject
                  - s3:Replicate*
                  - s3:RestoreObject
                Resource: '*'

  WorkerNodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Condition: cCreateWorkerNodeInstanceProfile
    Properties:
      Path: "/"
      Roles:
        - !Ref WorkerNodeRole

  VpcCidrSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W40 # Allow full egress
          - id: W5  # Allow full egress
          - id: W27 # Allow ingress through port range
          - id: W36 # Descriptions not necessary
    Properties:
      VpcId: !Ref pVPCID
      GroupDescription: Allows for communication on Condor ports from VPC
      SecurityGroupEgress:
        - IpProtocol: "-1"
          CidrIp: 0.0.0.0/0
      SecurityGroupIngress:
        - IpProtocol: tcp
          CidrIp: !Ref pAllowedCidrIp
          FromPort: 9618
          ToPort: 9618
        - IpProtocol: tcp
          CidrIp: !Ref pAllowedCidrIp
          FromPort: 9700
          ToPort: 9710

  SelfReferencingSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W40 # Allow full egress
          - id: W5  # Allow full egress
          - id: W27 # Allow ingress through port range
          - id: W36 # Descriptions not necessary
    Properties:
      VpcId: !Ref pVPCID
      GroupDescription: Allows for communication between the Condor nodes
      SecurityGroupEgress:
        - IpProtocol: "-1"
          CidrIp: 0.0.0.0/0

  SelfReferencingSecurityGroupIngressCondor:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow port 9618 inbound from self
      GroupId: !Ref SelfReferencingSecurityGroup
      SourceSecurityGroupId: !Ref SelfReferencingSecurityGroup
      FromPort: 9618
      ToPort: 9618
      IpProtocol: tcp

  SelfReferencingSecurityGroupIngressCondorExtraPorts:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow port 9700-9710 inbound from self
      GroupId: !Ref SelfReferencingSecurityGroup
      SourceSecurityGroupId: !Ref SelfReferencingSecurityGroup
      FromPort: 9700
      ToPort: 9710
      IpProtocol: tcp

  EfsSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W40 # Allow full egress
          - id: W5  # Allow full egress
          - id: W36 # Descriptions not necessary
    Properties:
      VpcId: !Ref pVPCID
      GroupDescription: HTCondor Product EFS Communication
      SecurityGroupEgress:
        - IpProtocol: "-1"
          CidrIp: 0.0.0.0/0
      SecurityGroupIngress:
        - IpProtocol: tcp
          SourceSecurityGroupId: !Ref SelfReferencingSecurityGroup
          FromPort: 2049
          ToPort: 2049

  # EFS
  FileSystem:
    Condition: cCreateFileSystem
    Type: AWS::EFS::FileSystem
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Encrypted: true
      BackupPolicy:
        Status: ENABLED
      FileSystemTags:
        - Key: Name
          Value: !Sub "${pNamePrefix} HTCondor FileSystem"
  MountTargetA:
    Type: AWS::EFS::MountTarget
    Properties:
      FileSystemId: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
      SecurityGroups:
        - !Ref EfsSecurityGroup
      SubnetId: !Select [ '0', !Ref pSubnets ]
  MountTargetB:
    Type: AWS::EFS::MountTarget
    Properties:
      FileSystemId: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
      SecurityGroups:
        - !Ref EfsSecurityGroup
      SubnetId: !Select [ '1', !Ref pSubnets ]
  MountTargetC:
    Type: AWS::EFS::MountTarget
    Properties:
      FileSystemId: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
      SecurityGroups:
        - !Ref EfsSecurityGroup
      SubnetId: !Select [ '2', !Ref pSubnets ]

  WorkerNodeAutoscalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn: ControlNodeInstance
    Properties:
      MixedInstancesPolicy: !If
        - cUseSpotInstances
        - InstancesDistribution:
            OnDemandAllocationStrategy: prioritized
            OnDemandPercentageAboveBaseCapacity: 0
            SpotAllocationStrategy: lowest-price
            SpotInstancePools: 3
          LaunchTemplate:
            LaunchTemplateSpecification:
              LaunchTemplateId: !Ref WorkerNodeLaunchTemplate
              Version: !GetAtt "WorkerNodeLaunchTemplate.LatestVersionNumber"
            Overrides:
              - InstanceType: !Ref pWorkerNodeInstanceType
              - InstanceType: !If [ cSpotType1Exists, !Ref pWorkerSpotNodeInstanceType1, !Ref "AWS::NoValue"]
              - InstanceType: !If [ cSpotType2Exists, !Ref pWorkerSpotNodeInstanceType2, !Ref "AWS::NoValue"]
              - InstanceType: !If [ cSpotType3Exists, !Ref pWorkerSpotNodeInstanceType3, !Ref "AWS::NoValue"]
        - !Ref "AWS::NoValue"
      HealthCheckGracePeriod: 120
      HealthCheckType: EC2
      LaunchTemplate: !If
        - cUseSpotInstances
        - !Ref "AWS::NoValue"
        - LaunchTemplateId: !Ref WorkerNodeLaunchTemplate
          Version: !GetAtt "WorkerNodeLaunchTemplate.LatestVersionNumber"
      MetricsCollection:
        - Granularity: 1Minute
      MaxSize: !Ref pNumberOfWorkerNodes
      MinSize: "0"
      DesiredCapacity: !Ref pNumberOfWorkerNodes
      VPCZoneIdentifier: !Ref pSubnets
      Tags:
        - Key: Name
          Value: !Sub "${pNamePrefix} HTCondor Worker Node"
          PropagateAtLaunch: true
    CreationPolicy:
      ResourceSignal:
        Timeout: PT30M
        Count: 0
    UpdatePolicy:
      AutoScalingReplacingUpdate:
        WillReplace: true
      AutoScalingRollingUpdate:
        MaxBatchSize: 1
        MinInstancesInService: 1
        PauseTime: PT20M
        WaitOnResourceSignals: true
      AutoScalingScheduledAction:
        IgnoreUnmodifiedGroupSizeProperties: true

  WorkerNodeLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        BlockDeviceMappings:
          - DeviceName: /dev/sda1
            Ebs:
              VolumeSize: !Ref pWorkerNodeVolumeSize
              DeleteOnTermination: true
        EbsOptimized: false
        IamInstanceProfile:
          Name: !If [ cCreateWorkerNodeInstanceProfile, !Ref WorkerNodeInstanceProfile, !Ref pWorkerNodeInstanceProfile ]
        ImageId: !Ref pWorkerNodeAmiId
        Monitoring:
          Enabled: true
        InstanceType: !Ref pWorkerNodeInstanceType
        SecurityGroupIds:
          - !Ref SelfReferencingSecurityGroup
        UserData:
          Fn::Base64: !Sub |
            #!/bin/bash -x

            yum update -y

            REGION="${AWS::Region}"
            /opt/aws/bin/aws configure set default.region ${AWS::Region}
            STACK_NAME=${AWS::StackName}

            function error_exit {
              /opt/aws/bin/cfn-signal --exit-code 1 --reason '$1' --stack $STACK_NAME --resource WorkerNodeAutoscalingGroup
              exit 1
            }

            #  Copy EC2 tags to the EBS root volume
            INSTANCE_ID=$( curl http://169.254.169.254/latest/meta-data/instance-id )
            VOL=$(=/bin/aws ec2 describe-volumes --filters Name=attachment.instance-id,Values=$INSTANCE_ID Name=attachment.device,Values=/dev/sda1 --query Volumes[].VolumeId --output text )
            EC2_TAGS=$(=/bin/aws ec2 describe-tags --filters Name=resource-id,Values=$INSTANCE_ID --query 'Tags[?!starts_with(Key, `aws`) == `true`].{Value:Value,Key:Key}' )
            /bin/aws ec2 create-tags --resources $VOL --tags "$EC2_TAGS"

            /opt/aws/bin/cfn-init -v --region $REGION --stack $STACK_NAME --resource WorkerNodeLaunchTemplate --configsets ascending || error_exit 'Failed to run cfn-init.'
            /opt/aws/bin/cfn-hup || error_exit 'Failed to start cfn-hup'
            /opt/aws/bin/cfn-signal --region $REGION --success true --stack $STACK_NAME --resource WorkerNodeAutoscalingGroup
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          ascending:
            - 01-config
            - 02-mount-efs
            - 03-install-base-packages
            - 04-install-condor
            - 05-configure-condor-worker
            - 06-upgrade-to-awscliv2

        01-config:
          files:
            /etc/ansible/ansible.cfg:
              content: |
                [defaults]
                log_path = /var/log/ansible.log

            /etc/cfn/cfn-hup.conf:
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region}
                verbose=true
              mode: '000400'
              owner: root
              group: root

            /etc/cfn/hooks.d/cfn-auto-reloader.conf:
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.WorkerNodeLaunchTemplate.Metadata.AWS::CloudFormation::Init
                action=/usr/bin/cfn-init -v --stack ${AWS::StackName} --resource WorkerNodeLaunchTemplate --configsets ascending --region ${AWS::Region}
                runas=root
            /etc/sysctl.d/98-open-files.conf:
              content: 'fs.file-max = 100000

                '
              owner: root
              group: root
              mode: '000644'
          services:
            sysvinit:
              cfn-hup:
                enabled: 'true'
                ensureRunning: 'true'
                files:
                  - /etc/cfn/cfn-hup.conf
                  - /etc/cfn/hooks.d/cfn-auto-reloader.conf
          commands:
            00-set-sysctl-values:
              command: sudo sysctl -p
            01-set-ulimit-values:
              command: sudo echo "* hard nofile 100000" >> /etc/security/limits.conf && sudo echo "* soft nofile 100000" >> /etc/security/limits.conf
        02-mount-efs:
          commands:
            00-make-mountdir:
              command: mkdir -p /mnt/condor_working
            01-mount-efs:
              command: !Sub
                - "sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport ${efs_id}.efs.${AWS::Region}.amazonaws.com:/ /mnt/condor_working"
                - efs_id: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
            02-set-mountdir-permissions:
              command: sudo chmod go+rw /mnt/condor_working
        03-install-base-packages:
          packages:
            yum:
              git: []
              jq: []
              wget: []
              screen: []
              emacs: []
        04-install-condor:
          packages:
            yum:
              iptables-services: []
          commands:
            00-install-condor:
              command: curl -fsSL https://get.htcondor.org | GET_HTCONDOR_PASSWORD="HTCondor10#" /bin/bash -s -- --no-dry-run --channel stable
        05-configure-condor-worker:
          files:
            /etc/condor/config.d/config:
              content: !Sub |
                  CONDOR_HOST = ${ControlNodeInstance.PrivateIp}
                  COLLECTOR_HOST = $(CONDOR_HOST)
                  ALLOW_READ = *
                  ALLOW_WRITE = *
                  ALLOW_ADMINISTRATOR = $(CONDOR_HOST),  $(IP_ADDRESS)
                  SLOT_TYPE_1 = cpu=100%
                  NUM_SLOTS_TYPE_1 = 1
                  SLOT_TYPE_1_PARTITIONABLE = True
                  DAEMON_LIST = MASTER, STARTD, SCHEDD
                  FILESYSTEM_DOMAIN = htcondor.efs
                  DOCKER_VOLUMES = CONDOR_EFS
                  DOCKER_VOLUME_DIR_CONDOR_EFS = /mnt/condor_working
                  DOCKER_MOUNT_VOLUMES = CONDOR_EFS
                  use role:get_htcondor_execute
              mode: '000444'
              owner: root
              group: root
          commands:
            00-set-condor-password:
              command: echo -n "HTCondor10#" | sh -c "condor_store_cred add -c -i -"
            01-issue-condor-token:
              command: !Sub "sh -c 'umask 0077; condor_token_create -identity condor@${ControlNodeInstance.PrivateIp} > /etc/condor/tokens.d/condor@${ControlNodeInstance.PrivateIp}'"
            02-configure-iptables-condor-port:
              command: iptables -I INPUT -i eth0 -p tcp --dport 9618 -j ACCEPT && service iptables save
            03-configure-iptables-PEST-port:
              command: iptables -I INPUT -i eth0 -p tcp --dport 9700:9710 -j ACCEPT && service iptables save
            04-remove-default-config-files:
              command: rm -f /etc/condor/config.d/00-htcondor-9.0.config /etc/condor/config.d/00-minicondor
            05-restart-condor:
              command: systemctl restart condor
        06-upgrade-to-awscliv2:
          sources:
            /root/awscliv2: https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
          commands:
            00-remove-v1:
              command: yum remove -y awscli
            01-install-v2:
              command: /root/awscliv2/aws/install -i /usr/local/aws
            02-make-symlink:
              command: ln -s /usr/local/bin/aws /bin/aws
            03-cleanup:
              command: rm -rf /root/awscliv2

  # ### Control Node
  ControlNodeInstance:
    Type: AWS::EC2::Instance
    Properties:
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: !Ref pControlNodeVolumeSize
            DeleteOnTermination: true
      EbsOptimized: false
      IamInstanceProfile: !If [ cCreateControlNodeInstanceProfile, !Ref ControlNodeInstanceProfile, !Ref pControlNodeInstanceProfile ]
      ImageId: !Ref pControlNodeAmiId
      Monitoring: true
      InstanceType: !Ref pControlNodeInstanceType
      SecurityGroupIds:
        - !Ref SelfReferencingSecurityGroup
        - !Ref VpcCidrSecurityGroup
      SubnetId: !Select [ 0, !Ref pSubnets ]
      Tags:
        - Key: Name
          Value: !Sub "${pNamePrefix} HTCondor Control Node"
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -x

          yum update -y

          REGION="${AWS::Region}"
          /bin/aws configure set default.region ${AWS::Region}
          STACK_NAME=${AWS::StackName}

          function error_exit {
            /opt/aws/bin/cfn-signal --exit-code 1 --reason '$1' --stack $STACK_NAME --resource WorkerNodeAutoscalingGroup
            exit 1
          }

          #  Copy EC2 tags to the EBS root volume
          INSTANCE_ID=$( curl http://169.254.169.254/latest/meta-data/instance-id )
          VOL=$(/bin/aws ec2 describe-volumes --filters Name=attachment.instance-id,Values=$INSTANCE_ID Name=attachment.device,Values=/dev/sda1 --query Volumes[].VolumeId --output text )
          EC2_TAGS=$(/bin/aws ec2 describe-tags --filters Name=resource-id,Values=$INSTANCE_ID --query 'Tags[?!starts_with(Key, `aws`) == `true`].{Value:Value,Key:Key}' )
          /bin/aws ec2 create-tags --resources $VOL --tags "$EC2_TAGS"

          /opt/aws/bin/cfn-init -v --region $REGION --stack $STACK_NAME --resource ControlNodeInstance --configsets ascending || error_exit 'Failed to run cfn-init.'
          /opt/aws/bin/cfn-hup || error_exit 'Failed to start cfn-hup'
          /opt/aws/bin/cfn-signal --region $REGION --success true --stack $STACK_NAME --resource ControlNodeInstance
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          ascending:
            - 01-config
            - 02-mount-efs
            - 03-install-base-packages
            - 04-install-condor
            - 05-configure-condor-controller
            - 06-upgrade-to-awscliv2

        01-config:
          files:
            /etc/ansible/ansible.cfg:
              content: |
                [defaults]
                log_path = /var/log/ansible.log

            /etc/cfn/cfn-hup.conf:
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region}
                verbose=true
              mode: '000400'
              owner: root
              group: root

            /etc/sysctl.d/98-open-files.conf:
              content: 'fs.file-max = 100000

                '
              owner: root
              group: root
              mode: '000644'

            /etc/cfn/hooks.d/cfn-auto-reloader.conf:
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.ControlNodeInstance.Metadata.AWS::CloudFormation::Init
                action=/usr/bin/cfn-init -v --stack ${AWS::StackName} --resource ControlNodeInstance --configsets ascending --region ${AWS::Region}
                runas=root
          services:
            sysvinit:
              cfn-hup:
                enabled: 'true'
                ensureRunning: 'true'
                files:
                  - /etc/cfn/cfn-hup.conf
                  - /etc/cfn/hooks.d/cfn-auto-reloader.conf
          commands:
            00-set-sysctl-values:
              command: sudo sysctl -p
            01-set-ulimit-values:
              command: sudo echo "* hard nofile 100000" >> /etc/security/limits.conf && sudo echo "* soft nofile 100000" >> /etc/security/limits.conf
        02-mount-efs:
          commands:
            00-make-mountdir:
              command: mkdir -p /mnt/condor_working
            01-mount-efs:
              command: !Sub
                - "sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport ${efs_id}.efs.${AWS::Region}.amazonaws.com:/ /mnt/condor_working"
                - efs_id: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
            02-set-mountdir-permissions:
              command: sudo chmod go+rw /mnt/condor_working
            03-mount-efs-on-reboot:
              command: !Sub
                - "sudo echo '${efs_id}.efs.${AWS::Region}.amazonaws.com:/ /mnt/condor_working nfs4 nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport,_netdev 0 0' >> /etc/fstab"
                - efs_id: !If [ cCreateFileSystem, !Ref FileSystem, !Ref pEfsId ]
        03-install-base-packages:
          packages:
            yum:
              git: []
              jq: []
              wget: []
              screen: []
              emacs: []
        04-install-condor:
          packages:
            yum:
              iptables-services: []
          commands:
            00-install-condor:
              command: curl -fsSL https://get.htcondor.org | GET_HTCONDOR_PASSWORD="HTCondor10#" /bin/bash -s -- --no-dry-run --channel stable
        05-configure-condor-controller:
          files:
            /etc/condor/config.d/config:
              content: |
                CONDOR_HOST = replaceme
                ALLOW_READ = *
                ALLOW_WRITE = *
                ALLOW_ADMINISTRATOR = $(CONDOR_HOST),  $(IP_ADDRESS)
                DAEMON_LIST = MASTER, COLLECTOR, SCHEDD, NEGOTIATOR
                FILESYSTEM_DOMAIN = htcondor.efs
                use role:get_htcondor_central_manager
                use role:get_htcondor_submit
              mode: '000644'
              owner: root
              group: root
            /home/ssm-user/sleep.sh:
              content: |
                #!/bin/bash
                # sleep.sh -- simple sleep script for condor
                # sleep.sh and sleep.sub are available to test condor via "condor_submit sleep.sub"
                TIMETOWAIT="6"
                echo "sleeping for $TIMETOWAIT seconds"
                /bin/sleep $TIMETOWAIT
            /home/ssm-user/sleep.sub:
              content: |
                # sleep.sub -- simple sleep condor job submission
                # sleep.sh and sleep.sub are available to test condor via "condor_submit sleep.sub"
                executable              = sleep.sh
                log                     = sleep.log
                output                  = outfile.txt
                error                   = errors.txt
                should_transfer_files   = Yes
                when_to_transfer_output = ON_EXIT
                queue
          commands:
            00-update-condor-file:
              command: export MY_IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4) && /bin/sed -i "s/replaceme/$MY_IP/g" /etc/condor/config.d/config
            01-set-condor-password:
              command: echo -n "HTCondor10#" | sh -c "condor_store_cred add -c -i -"
            02-issue-condor-token:
              command: export MY_IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4) && sh -c "umask 0077; condor_token_create -identity condor@${MY_IP} > /etc/condor/tokens.d/condor@${MY_IP}"
            03-configure-iptables:
              command: iptables -I INPUT -i eth0 -p tcp --dport 9618 -j ACCEPT && service iptables save
            04-configure-iptables-PEST-port:
              command: iptables -I INPUT -i eth0 -p tcp --dport 9700:9710 -j ACCEPT && service iptables save
            05-remove-default-config-files:
              command: rm -f /etc/condor/config.d/00-htcondor-9.0.config /etc/condor/config.d/00-minicondor
            06-restart-condor:
              command: systemctl restart condor
        06-upgrade-to-awscliv2:
          sources:
            /root/awscliv2: https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
          commands:
            00-remove-v1:
              command: yum remove -y awscli
            01-install-v2:
              command: /root/awscliv2/aws/install -i /usr/local/aws
            02-make-symlink:
              command: ln -s /usr/local/bin/aws /bin/aws
            03-cleanup:
              command: rm -rf /root/awscliv2
